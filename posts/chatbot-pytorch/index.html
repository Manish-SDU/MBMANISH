<!DOCTYPE html><html lang="en">
<!-- Mirrored from www.python-engineer.com/posts/chatbot-pytorch/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 04 Sep 2022 12:01:53 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head><meta charset="UTF-8"/><meta name="og:site_name" content="Python Engineer"/><link rel="canonical" href="https://python-engineer.com/posts/chatbot-pytorch"/><meta name="twitter:url" content="https://python-engineer.com/posts/chatbot-pytorch"/><meta name="og:url" content="https://python-engineer.com/posts/chatbot-pytorch"/><title>Chat Bot With PyTorch - NLP And Deep Learning | Python Engineer</title><meta name="twitter:title" content="Chat Bot With PyTorch - NLP And Deep Learning | Python Engineer"/><meta name="og:title" content="Chat Bot With PyTorch - NLP And Deep Learning | Python Engineer"/><meta name="description" content="In this tutorial we build a simple chatbot in PyTorch. I will also provide an introduction to some basic Natural Language Processing (NLP) techniques."/><meta name="twitter:description" content="In this tutorial we build a simple chatbot in PyTorch. I will also provide an introduction to some basic Natural Language Processing (NLP) techniques."/><meta name="og:description" content="In this tutorial we build a simple chatbot in PyTorch. I will also provide an introduction to some basic Natural Language Processing (NLP) techniques."/><meta name="twitter:card" content="summary"/><link rel="stylesheet" href="../../styles.css" type="text/css"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><link rel="shortcut icon" href="../../images/favicon.png" type="image/png"/><link rel="alternate" href="../../feed.rss" type="application/rss+xml" title="Subscribe to Python Engineer"/><meta name="twitter:image" content="../../images/icon.png"/><meta name="og:image" content="../../images/icon.png"/><script async defer data-domain="python-engineer.com" src="../../../plausible.io/js/plausible.js"></script></head><body class="item"><header><div class="header-promotion"><p><div class="wrapper"><p><a href="https://pythonengineer.pallet.com/" target="_blank">üêç Find Python and ML Jobs! üêç</a></p></div></p></div><div class="wrapper"><nav><ul><li class="selected"><a href="../index.html">POSTS</a></li><li><a href="../../courses/index.html">COURSES</a></li><li><a href="../../about/index.html">ABOUT</a></li></ul></nav><a href="../../index.html"><div class="hero-container"><img class="header-image-small" src="../../images/pat_face_bg.webp" alt="Patrick Loeber"/><div class="hero-text-container justify-center"><p>Become a</p><h1 class="colorized-text ">Python Engineer</h1><p class="mobile-hide">Come and learn about</p><ul class="mobile-hide"><li><a class="variant-a" href="../../tags/python/index.html">Python</a></li><li id="regular-li">and</li><li><a class="variant-b" href="../../tags/machine-learning/index.html">Machine Learning</a></li></ul></div></div></a></div></header><article class="page wrapper post-page"><h1 class="blog-header">Chat Bot With PyTorch - NLP And Deep Learning</h1><div class="metadata"><ul class="tags"><li class="variant-c"><a href="../../tags/pytorch/index.html">PyTorch</a></li><li class="variant-c"><a href="../../tags/deep-learning/index.html">Deep Learning</a></li><li class="variant-e"><a href="../../tags/nlp/index.html">NLP</a></li></ul><span class="post-date">14 Jun 2020, by </span><a class="author-link-post" href="../../authors/patrick/index.html">Patrick Loeber</a></div><div class="video-player"><iframe frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="true" src="https://www.youtube-nocookie.com/embed/RpWeNzfSUHw"></iframe></div><div class="content page-content m-top"><p>In this tutorial we build a simple chatbot in PyTorch. I will also provide an introduction to some basic Natural Language Processing (NLP) techniques.</p><pre><code><div class="highlight"><span></span><span class="go">&gt;&gt;&gt; Let&#39;s chat! (type &#39;quit&#39; to exit)</span>
<span class="go">&gt;&gt;&gt; You: Hi</span>
<span class="go">&gt;&gt;&gt; Hi there, what can I do for you?</span>
<span class="go">&gt;&gt;&gt; You: What do you sell?</span>
<span class="go">&gt;&gt;&gt; We have coffee and tea.</span>
</div></code></pre><p>Here's an overview of what you will learn:</p><ul><li>NLP Basics: Tokenization, Stemming, Bag Of Words</li><li>How to preprocess the data with <code>nltk</code>to feed it to your neural net</li><li>How to implement the feed-forward neural net in Pytorch and train it</li><li>The implementation should be easy to follow for beginners and provide a basic understanding of chatbots.</li><li>The implementation is straightforward with a Feed Forward Neural net with 2 hidden layers.</li><li>Customization for your own use case is super easy. Just modify <code>intents.json</code> with possible patterns and responses and re-run the training (see below for more info).</li></ul><p>The approach is inspired by this article and ported to PyTorch: <a href="https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077">https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077</a>.</p><p>You can find the code on <a href="https://github.com/python-engineer/pytorch-chatbot">GitHub</a>.</p><h2>1) Setup Your Environment</h2><p>Let's start by setting up our virtual environment and installing <code>PyTorch</code> and <code>nltk</code>.</p><h3>Create an environment</h3><p>Whatever you prefer (e.g. <code>conda</code> or <code>venv</code>)</p><pre><code><div class="highlight"><span></span><span class="go">mkdir myproject</span>
<span class="gp">$ </span><span class="nb">cd</span> myproject
<span class="gp">$ </span>python3 -m venv venv
</div></code></pre><h3>Activate it</h3><p>Mac / Linux:</p><pre><code><div class="highlight"><span></span><span class="go">. venv/bin/activate</span>
</div></code></pre><p>Windows:</p><pre><code><div class="highlight"><span></span><span class="go">venv\Scripts\activate</span>
</div></code></pre><h3>Install PyTorch and dependencies</h3><p>For Installation of PyTorch see <a href="https://pytorch.org/">official website</a>.</p><p>You also need <code>nltk</code>:</p><pre><code><div class="highlight"><span></span><span class="go">pip install nltk</span>
</div></code></pre><p>If you get an error during the first run, you also need to install <code>nltk.tokenize.punkt</code>: Run this once in your terminal:</p><pre><code><div class="highlight"><span></span><span class="gp">$ </span>python
<span class="go">&gt;&gt;&gt; import nltk</span>
<span class="go">&gt;&gt;&gt; nltk.download(&#39;punkt&#39;)</span>
</div></code></pre><h2>2) Create Training Data</h2><p>We need to create training data in a json file (<code>intents.json</code>). It has the following structure:</p><pre><code><div class="highlight"><span></span><span class="p">{</span>
  <span class="s2">&quot;intents&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;tag&quot;</span><span class="p">:</span> <span class="s2">&quot;greeting&quot;</span><span class="p">,</span>
      <span class="s2">&quot;patterns&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Hi&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Hey&quot;</span><span class="p">,</span>
        <span class="s2">&quot;How are you&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Is anyone there?&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Hello&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Good day&quot;</span>
      <span class="p">],</span>
      <span class="s2">&quot;responses&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Hey :-)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Hello, thanks for visiting&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Hi there, what can I do for you?&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Hi there, how can I help?&quot;</span>
      <span class="p">]</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</div></code></pre><p>You can customize it according to your own use case. Just define a new <code>tag</code>, possible <code>patterns</code>, and possible <code>responses</code> for the chat bot. You have to re-run the training whenever this file is modified.</p><h2>3) NLP Basics</h2><p>We can't just pass the input sentence as it is to our neural net. We somehow have to convert the pattern strings to numbers that the network can understand. For this we convert each sentence to a so called <strong>bag of words</strong> (bow). To do this we need to collect training words, i. e., all the words that our bot can have a look at in the training data. Based on all these words, we can then calculate the bag of word for each new sentence. A bag of words has the same size as the <em>all words</em> array, and each position contains a 1 if the word is avaliable in the incoming sentence, or 0 otherwise. Here's a visual example:</p><img src="../../images/2020-06-14-chatbot-pytorch/bag.png"Bag of Words"" alt="alt text"/><p>Before we can calculate the bow, we apply two more NLP techniques: <strong>Tokenization and Stemming</strong>.</p><ul><li>Tokenization: Splitting a string into meaningful units (e.g. words, punctuation characters, numbers)</li></ul><p>Example:</p><pre><code><div class="highlight"><span></span><span class="s2">&quot;what would you do with 1000000$?&quot;</span>
<span class="p">[</span> <span class="err">‚Äú</span><span class="n">what</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">would</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">you</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">do</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="k">with</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="mi">1000000</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú$‚Äù</span><span class="p">,</span> <span class="err">‚Äú?‚Äù</span><span class="p">]</span>
</div></code></pre><ul><li>Stemming Generate the root form of the words. It's a crude heuristic that chops of the ends off of words</li></ul><p>Example:</p><pre><code><div class="highlight"><span></span><span class="p">[</span><span class="err">‚Äú</span><span class="n">organize</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">organizes</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">organizing</span><span class="err">‚Äù</span><span class="p">]</span>
<span class="p">[</span> <span class="err">‚Äú</span><span class="n">organ</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">organ</span><span class="err">‚Äù</span><span class="p">,</span> <span class="err">‚Äú</span><span class="n">organ</span><span class="err">‚Äù</span><span class="p">]</span>
</div></code></pre><p>For our labels, we sort them alphabetically and then use the index as class label. Our whole preprocessing pipeline looks like this: <img src="../../images/2020-06-14-chatbot-pytorch/nlp.png"NLP Preprocessing Pipeline"" alt="alt text"/></p><h2>4) Implement The NLP Utils</h2><p>For this we use the <code>nltk</code> module. NLTK (<a href="https://www.nltk.org/">Natural Language Toolkit</a>) is a leading platform for building Python programs to work with human language data. It provides a lot of helpful methods that we can use.</p><pre><code><div class="highlight"><span></span><span class="c1"># nltk_utils.py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="c1"># nltk.download(&#39;punkt&#39;)</span>
<span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    split sentence into array of words/tokens</span>
<span class="sd">    a token can be a word or punctuation character, or number</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">stem</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    stemming = find the root form of the word</span>
<span class="sd">    examples:</span>
<span class="sd">    words = [&quot;organize&quot;, &quot;organizes&quot;, &quot;organizing&quot;]</span>
<span class="sd">    words = [stem(w) for w in words]</span>
<span class="sd">    -&gt; [&quot;organ&quot;, &quot;organ&quot;, &quot;organ&quot;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">bag_of_words</span><span class="p">(</span><span class="n">tokenized_sentence</span><span class="p">,</span> <span class="n">words</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    return bag of words array:</span>
<span class="sd">    1 for each known word that exists in the sentence, 0 otherwise</span>
<span class="sd">    example:</span>
<span class="sd">    sentence = [&quot;hello&quot;, &quot;how&quot;, &quot;are&quot;, &quot;you&quot;]</span>
<span class="sd">    words = [&quot;hi&quot;, &quot;hello&quot;, &quot;I&quot;, &quot;you&quot;, &quot;bye&quot;, &quot;thank&quot;, &quot;cool&quot;]</span>
<span class="sd">    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># stem each word</span>
    <span class="n">sentence_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokenized_sentence</span><span class="p">]</span>
    <span class="c1"># initialize bag with 0 for each word</span>
    <span class="n">bag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence_words</span><span class="p">:</span> 
            <span class="n">bag</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">bag</span>
</div></code></pre><h2>5) Implement The Neural Network</h2><p>The implementation is straightforward with a Feed Forward Neural net with 2 hidden layers:</p><pre><code><div class="highlight"><span></span><span class="c1"># model.py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">NeuralNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">l3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="c1"># no activation and no softmax at the end</span>
        <span class="k">return</span> <span class="n">out</span>
</div></code></pre><h2>6) Implement The Training Pipeline</h2><p>Put everything together:</p><pre><code><div class="highlight"><span></span><span class="c1"># train.py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">nltk_utils</span> <span class="kn">import</span> <span class="n">bag_of_words</span><span class="p">,</span> <span class="n">tokenize</span><span class="p">,</span> <span class="n">stem</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">NeuralNet</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;intents.json&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">intents</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">all_words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tags</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">xy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># loop through each sentence in our intents patterns</span>
<span class="k">for</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">intents</span><span class="p">[</span><span class="s1">&#39;intents&#39;</span><span class="p">]:</span>
    <span class="n">tag</span> <span class="o">=</span> <span class="n">intent</span><span class="p">[</span><span class="s1">&#39;tag&#39;</span><span class="p">]</span>
    <span class="c1"># add to tag list</span>
    <span class="n">tags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="n">intent</span><span class="p">[</span><span class="s1">&#39;patterns&#39;</span><span class="p">]:</span>
        <span class="c1"># tokenize each word in the sentence</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
        <span class="c1"># add to our words list</span>
        <span class="n">all_words</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="c1"># add to xy pair</span>
        <span class="n">xy</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">tag</span><span class="p">))</span>

<span class="c1"># stem and lower each word</span>
<span class="n">ignore_words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;?&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">]</span>
<span class="n">all_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">stem</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">all_words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignore_words</span><span class="p">]</span>
<span class="c1"># remove duplicates and sort</span>
<span class="n">all_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">all_words</span><span class="p">))</span>
<span class="n">tags</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tags</span><span class="p">))</span>

<span class="c1"># create training data</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">pattern_sentence</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span> <span class="ow">in</span> <span class="n">xy</span><span class="p">:</span>
    <span class="c1"># X: bag of words for each pattern_sentence</span>
    <span class="n">bag</span> <span class="o">=</span> <span class="n">bag_of_words</span><span class="p">(</span><span class="n">pattern_sentence</span><span class="p">,</span> <span class="n">all_words</span><span class="p">)</span>
    <span class="n">X_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bag</span><span class="p">)</span>
    <span class="c1"># y: PyTorch CrossEntropyLoss needs only class labels, not one-hot</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">tags</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">y_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Hyper-parameters </span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ChatDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_data</span> <span class="o">=</span> <span class="n">X_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_data</span> <span class="o">=</span> <span class="n">y_train</span>

    <span class="c1"># support indexing such that dataset[i] can be used to get i-th sample</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_data</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="c1"># we can call len(dataset) to return the size</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ChatDataset</span><span class="p">()</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss and optimizer</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Forward pass</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="c1"># if y would be one-hot, we must apply</span>
        <span class="c1"># labels = torch.max(labels, 1)[1]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="c1"># Backward and optimize</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">], Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;final loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
<span class="s2">&quot;model_state&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
<span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="n">input_size</span><span class="p">,</span>
<span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="n">hidden_size</span><span class="p">,</span>
<span class="s2">&quot;output_size&quot;</span><span class="p">:</span> <span class="n">output_size</span><span class="p">,</span>
<span class="s2">&quot;all_words&quot;</span><span class="p">:</span> <span class="n">all_words</span><span class="p">,</span>
<span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="n">tags</span>
<span class="p">}</span>

<span class="n">FILE</span> <span class="o">=</span> <span class="s2">&quot;data.pth&quot;</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">FILE</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training complete. file saved to </span><span class="si">{</span><span class="n">FILE</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</div></code></pre><h2>7) Implement The Chat</h2><p>Load the trained model and make predictions for new sentences:</p><pre><code><div class="highlight"><span></span><span class="p">#</span> <span class="n">chat</span><span class="p">.</span><span class="n">py</span>
<span class="kd">import</span> <span class="nc">random</span>
<span class="kd">import</span> <span class="nc">json</span>

<span class="kd">import</span> <span class="nc">torch</span>

<span class="n">from</span> <span class="n">model</span> <span class="kd">import</span> <span class="nc">NeuralNet</span>
<span class="n">from</span> <span class="n">nltk_utils</span> <span class="kd">import</span> <span class="nc">bag_of_words</span><span class="p">,</span> <span class="nc">tokenize</span>

<span class="n">device</span> <span class="p">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="err">&#39;</span><span class="n">cuda</span><span class="err">&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="err">&#39;</span><span class="n">cpu</span><span class="err">&#39;</span><span class="p">)</span>

<span class="n">with</span> <span class="n">open</span><span class="p">(</span><span class="err">&#39;</span><span class="n">intents</span><span class="p">.</span><span class="n">json</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">r</span><span class="err">&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_data</span><span class="p">:</span>
    <span class="n">intents</span> <span class="p">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_data</span><span class="p">)</span>

<span class="n">FILE</span> <span class="p">=</span> <span class="s">&quot;data.pth&quot;</span>
<span class="n">data</span> <span class="p">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">FILE</span><span class="p">)</span>

<span class="n">input_size</span> <span class="p">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&quot;input_size&quot;</span><span class="p">]</span>
<span class="n">hidden_size</span> <span class="p">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&quot;hidden_size&quot;</span><span class="p">]</span>
<span class="n">output_size</span> <span class="p">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&quot;output_size&quot;</span><span class="p">]</span>
<span class="n">all_words</span> <span class="p">=</span> <span class="n">data</span><span class="p">[</span><span class="err">&#39;</span><span class="n">all_words</span><span class="err">&#39;</span><span class="p">]</span>
<span class="n">tags</span> <span class="p">=</span> <span class="n">data</span><span class="p">[</span><span class="err">&#39;</span><span class="n">tags</span><span class="err">&#39;</span><span class="p">]</span>
<span class="n">model_state</span> <span class="p">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&quot;model_state&quot;</span><span class="p">]</span>

<span class="n">model</span> <span class="p">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">bot_name</span> <span class="p">=</span> <span class="s">&quot;Sam&quot;</span>
<span class="bp">print</span><span class="p">(</span><span class="s">&quot;Let&#39;s chat! (type &#39;quit&#39; to exit)&quot;</span><span class="p">)</span>
<span class="k">while</span> <span class="n">True</span><span class="p">:</span>
    <span class="p">#</span> <span class="n">sentence</span> <span class="p">=</span> <span class="s">&quot;do you use credit cards?&quot;</span>
    <span class="n">sentence</span> <span class="p">=</span> <span class="n">input</span><span class="p">(</span><span class="s">&quot;You: &quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sentence</span> <span class="p">==</span> <span class="s">&quot;quit&quot;</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="n">sentence</span> <span class="p">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="n">X</span> <span class="p">=</span> <span class="n">bag_of_words</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">all_words</span><span class="p">)</span>
    <span class="n">X</span> <span class="p">=</span> <span class="n">X</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">X</span> <span class="p">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">output</span> <span class="p">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="kc">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="p">=</span> <span class="n">torch</span><span class="p">.</span><span class="bp">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="p">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">tag</span> <span class="p">=</span> <span class="n">tags</span><span class="p">[</span><span class="n">predicted</span><span class="p">.</span><span class="n">item</span><span class="p">()]</span>

    <span class="n">probs</span> <span class="p">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="p">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">prob</span> <span class="p">=</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">predicted</span><span class="p">.</span><span class="n">item</span><span class="p">()]</span>
    <span class="k">if</span> <span class="n">prob</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.75</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">intent</span> <span class="k">in</span> <span class="n">intents</span><span class="p">[</span><span class="err">&#39;</span><span class="n">intents</span><span class="err">&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">tag</span> <span class="p">==</span> <span class="n">intent</span><span class="p">[</span><span class="s">&quot;tag&quot;</span><span class="p">]:</span>
                <span class="bp">print</span><span class="p">(</span><span class="n">f</span><span class="s">&quot;{bot_name}: {random.choice(intent[&#39;responses&#39;])}&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">print</span><span class="p">(</span><span class="n">f</span><span class="s">&quot;{bot_name}: I do not understand...&quot;</span><span class="p">)</span>
</div></code></pre><h2>8) Usage</h2><p>Congratulations! You have implemented your chat bot! Now just run the training and start chatting üòä.</p><p>Run</p><pre><code><div class="highlight"><span></span><span class="go">python train.py</span>
</div></code></pre><p>This will dump <code>data.pth</code> file. And then run</p><pre><code><div class="highlight"><span></span><span class="go">python chat.py</span>
</div></code></pre><p>As mentioned in the beginning, you can customize it for your own needs. Just modify <code>intents.json</code> with possible patterns and responses and re-run the training.</p></div><ul class="actions"><li><a class="youtube-button" href="https://www.youtube.com/channel/UCbXgNpp0jedKWcQiULLbDTA?sub_confirmation=1" target="_blank" rel="nofollow">Subscribe</a></li><li><a class="twitter-button" href="https://twitter.com/intent/tweet?via=python_engineer&amp;text=Chat%20Bot%20With%20PyTorch%20-%20NLP%20And%20Deep%20Learning&amp;url=https://python-engineer.com/posts/chatbot-pytorch" rel="nofollow" target="_blank">Share</a></li></ul><div class="affiliate-container"><div><h2>FREE VS Code / PyCharm Extensions I Use</h2><p>‚úÖ Write cleaner code with Sourcery, instant refactoring suggestions: <a href="https://sourcery.ai/?utm_source=youtube&amp;utm_campaign=pythonengineer" target="_blank">Link *</a></p><p class="affiliate-note">* This is an affiliate link. By clicking on it you will not have any additional costs, instead you will support me and my project. Thank you! üôè</p></div></div><a class="sponsor-container" href="../../newsletter/index.html" rel="nofollow"><img class="main" src="../../images/numpyhandbook.webp" alt="newsletter"/><div><h2>FREE NumPy Handbook</h2><p>Learn NumPy with this eBook! It covers code examples for all essential functions. Get it for free together with monthly Python tips and news.</p><button class="pill-button">I Want This</button></div></a><div><div><a class="section-header pad-top" href="../../courses/index.html"><h2>Check out my Courses</h2></a><ul class="item-list grid"><li><article class="post-card"><a href="../../courses/tensorflowbeginner/index.html"><img class="post-thumb" alt="Thumbnail image of the post." src="../../images/titles/tfcourse.webp"/></a><ul class="tags"><li class="variant-a"><a href="../../tags/python/index.html">Python</a></li><li class="variant-f"><a href="../../tags/tensorflow/index.html">TensorFlow</a></li><li class="variant-c"><a href="../../tags/deep-learning/index.html">Deep Learning</a></li></ul><a class="post-link" href="../../courses/tensorflowbeginner/index.html"><h1 class="description">TensorFlow 2 Beginner</h1><p>Learn all the necessary basics to get started with TensorFlow 2 and Keras.</p></a></article></li><li><article class="post-card"><a href="../../courses/pytorchbeginner/index.html"><img class="post-thumb" alt="Thumbnail image of the post." src="../../images/titles/pytorchcourse.webp"/></a><ul class="tags"><li class="variant-a"><a href="../../tags/python/index.html">Python</a></li><li class="variant-c"><a href="../../tags/pytorch/index.html">PyTorch</a></li><li class="variant-c"><a href="../../tags/deep-learning/index.html">Deep Learning</a></li></ul><a class="post-link" href="../../courses/pytorchbeginner/index.html"><h1 class="description">PyTorch Beginner</h1><p>Learn all the necessary basics to get started with this deep learning framework.</p></a></article></li><li><article class="post-card"><a href="../../courses/mlfromscratch/index.html"><img class="post-thumb" alt="Thumbnail image of the post." src="../../images/titles/mlfromscratch.webp"/></a><ul class="tags"><li class="variant-a"><a href="../../tags/python/index.html">Python</a></li><li class="variant-b"><a href="../../tags/machine-learning/index.html">Machine Learning</a></li><li class="variant-d"><a href="../../tags/numpy/index.html">numpy</a></li></ul><a class="post-link" href="../../courses/mlfromscratch/index.html"><h1 class="description">ML From Scratch</h1><p>Implement popular Machine Learning algorithms from scratch using only built-in Python modules and numpy.</p></a></article></li><li><article class="post-card"><a href="../../courses/advancedpython/index.html"><img class="post-thumb" alt="Thumbnail image of the post." src="../../images/titles/advancedpythoncourse.webp"/></a><ul class="tags"><li class="variant-a"><a href="../../tags/python/index.html">Python</a></li></ul><a class="post-link" href="../../courses/advancedpython/index.html"><h1 class="description">Advanced Python</h1><p>Advanced Python Tutorials. It covers topics like collections, decorators, generators, multithreading, logging, and much more.</p></a></article></li></ul></div></div></article><footer><div class="wrapper patreon-footer"><h1>Patreon</h1><p>Become a Patron and get exclusive content! Get access to ML From Scratch notebooks, join a private Discord channel, get priority response, and more!</p><div class="gold-patrons"><h3>Special thanks to my Gold Patreons:</h3><p>Tonja J R</p><p>Daniel And Andy</p><p>Sergei</p></div><p>And of course thanks to every other member! I really appreciate the support!</p><a href="https://www.patreon.com/patrickloeber" target="_blank">Find Out More</a></div><div class="wrapper"><p>Copyright ¬© Python Engineer 2022.</p><p>Generated using <a href="https://github.com/johnsundell/publish" target="_blank">Publish</a>.</p><ul class="footer-links"><li><a class="youtube-button youtube-icon" href="https://www.youtube.com/channel/UCbXgNpp0jedKWcQiULLbDTA" target="_blank">YouTube</a></li><li><a class="social-button twitter-button" href="https://twitter.com/python_engineer" target="_blank">Twitter</a></li><li><a class="social-button github-button" href="https://github.com/python-engineer" target="_blank">GitHub</a></li><li><a class="social-button discord-button" href="https://discord.gg/FHMg9tKFSN" target="_blank">Discord</a></li><li><a class="footer-button" href="../../feed.rss">RSS</a></li><li><a class="footer-button" href="../../about/index.html">Contact</a></li><li><a class="footer-button" href="../../legal-notice/index.html">Legal Notice</a></li><li><a class="footer-button" href="../../privacy-policy/index.html">Privacy Policy</a></li></ul></div></footer></body>
<!-- Mirrored from www.python-engineer.com/posts/chatbot-pytorch/ by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 04 Sep 2022 12:01:53 GMT -->
</html>